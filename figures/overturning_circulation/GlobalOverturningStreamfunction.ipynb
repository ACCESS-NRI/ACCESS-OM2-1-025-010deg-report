{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Overturning Streamfunction\n",
    "\n",
    "This scipt plots the global overturning streamfunction in density space for 3 ACCESS-OM2 simulations at different resolutions.\n",
    "\n",
    "It also serves as a sample for how to compute and display diagnostics for the ACCESS-OM2 model evaluation paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netcdf_index loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/157/amh157/.local/lib/python3.6/site-packages/cmocean/tools.py:76: MatplotlibDeprecationWarning: The is_string_like function was deprecated in version 2.1.\n",
      "  if not mpl.cbook.is_string_like(rgbin[0]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available exptdata keys:  ['1deg', '025deg', '01deg']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cosima_cookbook as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import IPython.display\n",
    "import cmocean as cm\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))  # so we can import ../exptdata\n",
    "import exptdata\n",
    "print('Available exptdata keys: ', [k for k in exptdata.exptdict.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "figdir = ''\n",
    "def savefigure(fname):\n",
    "    plt.savefig(os.path.join(figdir, fname+'.png'),dpi=300, bbox_inches=\"tight\")  # comment out to disable saving\n",
    "    plt.savefig(os.path.join(figdir, fname+'.pdf'),dpi=300, bbox_inches=\"tight\")  # comment out to disable saving\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the link to the dashboard below doesn't work, run this command on a local terminal to set up a SSH tunnel:\n",
      "\n",
      "  ssh -N -L 32781:127.0.0.1:32781 vdi-n3.nci.org.au -l amh157\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:39004\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:32781/status' target='_blank'>http://127.0.0.1:32781/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>24.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:39004' processes=4 cores=8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.start_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For starters**, list the three experiments you want to use. For now, we will use RYF sample runs - in the future we hope to be using the full interannual forcing simulations. This script assumes that there are 3 experiments, and that they are ordered as 1°, 0.25° then 0.1°."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function computes the overturning from ty_trans_rho (and ty_trans_rho_gm if the variable is present). It loads data from the last IAF cycle (specified as n_files in exptdata) and then averages from 1998 onwards (which will be the last two decades once all runs are complete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_psi_avg(ekey):\n",
    "    \n",
    "    \n",
    "    expt = exptdata.exptdict[ekey]['expt']\n",
    "    n_files = exptdata.exptdict[ekey]['n_files']\n",
    "    time_units = exptdata.exptdict[ekey]['time_units']\n",
    "    offset = exptdata.exptdict[ekey]['offset']\n",
    "    \n",
    "    ## Load overturning from ocean.nc file\n",
    "    psi = cc.get_nc_variable(expt, 'ocean.nc', 'ty_trans_rho',\n",
    "                          chunks={'potrho': None}, n=n_files,\n",
    "                          time_units=time_units, offset=offset)\n",
    "    psi = psi.sel(time=slice(pd.datetime(2008,1,1),None)).mean('time').sum('grid_xt_ocean')*1.0e-9\n",
    "    \n",
    "    ## If GM overturning is output, load that too\n",
    "    varlist = cc.get_variables(expt, 'ocean.nc')\n",
    "    if 'ty_trans_rho_gm' in varlist:\n",
    "        GM = True\n",
    "        psiGM = cc.get_nc_variable(expt, 'ocean.nc', 'ty_trans_rho_gm',\n",
    "                              chunks={'potrho': None}, n=n_files,\n",
    "                              time_units=time_units, offset=offset)\n",
    "        psiGM = psiGM.sel(time=slice(pd.datetime(2008,1,1),None)).mean('time').sum('grid_xt_ocean')*1.0e-9\n",
    "    else:\n",
    "        GM = False\n",
    "        \n",
    "    psi_avg = psi.cumsum('potrho') -  psi.sum('potrho')\n",
    "    if GM:\n",
    "        psi_avg = psi_avg + psiGM\n",
    "    \n",
    "    ## This function basically splits the calculation up to save on memory:\n",
    "    psi_avg = cc.compute_by_block(psi_avg)\n",
    "    #psi_avg = psi_avg.compute()\n",
    "    \n",
    "    return psi_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function plots the streamfunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psi(psi_avg, clev=np.arange(-25,25,2)):\n",
    "\n",
    "    p1 = plt.contourf(psi_avg.grid_yu_ocean, \n",
    "                 psi_avg.potrho, \n",
    "                 psi_avg, \n",
    "                 cmap=cm.cm.curl,levels=clev,extend='both')\n",
    "    plt.contour(psi_avg.grid_yu_ocean, \n",
    "                psi_avg.potrho, \n",
    "                psi_avg, levels=clev, colors='k', linewidths=0.25)\n",
    "    plt.contour(psi_avg.grid_yu_ocean,\n",
    "                psi_avg.potrho, psi_avg,\n",
    "                levels=[0.0,], colors='k', linewidths=0.5)\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    plt.ylim((1037.5,1034))\n",
    "    plt.ylabel('Potential Density (kg m$^{-3}$)')\n",
    "    plt.xlabel('Latitude ($^\\circ$N)')\n",
    "    plt.xlim([-75,85])\n",
    "    \n",
    "    return p1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the code to make the actual figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using database sqlite:////g/data3/hh5/tmp/cosima/cosima-cookbook/cosima-cookbook.db\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc52c06dd8a42c283922c56466b56ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='get_nc_variable:: ', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using database sqlite:////g/data3/hh5/tmp/cosima/cosima-cookbook/cosima-cookbook.db\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dddf8f808a95492b9a21ed80bb3ae1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='get_nc_variable:: ', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf2e0f202f34363939e4ce0e98a8b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Using database sqlite:////g/data3/hh5/tmp/cosima/cosima-cookbook/cosima-cookbook.db\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d70b03cdced4d798071ed25c2b8a177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='get_nc_variable:: ', max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using database sqlite:////g/data3/hh5/tmp/cosima/cosima-cookbook/cosima-cookbook.db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "clev=np.arange(-25,25,2)\n",
    "\n",
    "\n",
    "for i, ekey in enumerate(exptdata.exptdict.keys()):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    psi_avg = calc_psi_avg(ekey)\n",
    "    p1=plot_psi(psi_avg,clev)\n",
    "    \n",
    "plt.subplot(221)\n",
    "#plt.xlabel('')\n",
    "plt.title('(a) ACCESS-OM2')\n",
    "plt.subplot(222)\n",
    "#plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('(b) ACCESS-OM2-025')\n",
    "plt.subplot(223)\n",
    "plt.title('(c) ACCESS-OM2-01')\n",
    "\n",
    "plt.subplots_adjust(left=0.08,right=0.92)\n",
    "ax = plt.gca()\n",
    "tmp = ax.get_position(original=True)\n",
    "tmp.x0 = tmp.x0 + 0.23\n",
    "tmp.x1 = tmp.x1 + 0.23\n",
    "print(tmp)\n",
    "ax.set_position(tmp)\n",
    "\n",
    "ax1 = plt.axes([0.94,0.3,0.008,0.4])\n",
    "cb = plt.colorbar(p1,cax=ax1,orientation='vertical')\n",
    "ax1.xaxis.set_label_position(\"top\")\n",
    "cb.ax.set_xlabel('Sv')\n",
    "\n",
    "savefigure('mean_overturning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now compute timeseries of abyssal overturning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(122)\n",
    "for ekey in exptdata.exptdict.keys():\n",
    "    expt = exptdata.exptdict[ekey]['expt']\n",
    "    n_files = exptdata.exptdict[ekey]['n_files']\n",
    "    time_units = exptdata.exptdict[ekey]['time_units']\n",
    "    offset = exptdata.exptdict[ekey]['offset']\n",
    "    print(expt)\n",
    "    \n",
    "    psi = cc.get_nc_variable(expt, 'ocean.nc', 'ty_trans_rho',\n",
    "                            chunks={'potrho': None},n=n_files,\n",
    "                            time_units = time_units, offset=offset)\n",
    "    psi = psi.sum('grid_xt_ocean').sel(method='Nearest',grid_yu_ocean=-40)*1.0e-9\n",
    "    psi_sum = psi.cumsum('potrho') - psi.sum('potrho')\n",
    "    \n",
    "    ## If GM overturning is output, load that too\n",
    "    varlist = cc.get_variables(expt, 'ocean.nc')\n",
    "    if 'ty_trans_rho_gm' in varlist:\n",
    "        psiGM = cc.get_nc_variable(expt, 'ocean.nc', 'ty_trans_rho_gm',\n",
    "                            chunks={'potrho': None},n=n_files,\n",
    "                            time_units = time_units, offset=offset)\n",
    "        psiGM = psiGM.sum('grid_xt_ocean').sel(method='Nearest',grid_yu_ocean=-40)*1.0e-9\n",
    "        psi_sum = psi_sum + psiGM\n",
    "\n",
    "    psi_aabw = -psi_sum.sel(potrho=slice(1036,None))\\\n",
    "                .min('potrho').resample(time='A').mean('time')\n",
    "    psi_aabw.plot(label=exptdata.exptdict[ekey]['desc'])\n",
    "    \n",
    "plt.gca().autoscale()\n",
    "plt.ylabel('')\n",
    "plt.xlim([pd.datetime(1958,1,1),pd.datetime(2017,12,31)])\n",
    "plt.xlabel('Year')\n",
    "plt.title('(b) Abyssal overturning at 40°S')\n",
    "\n",
    "plt.subplot(121)\n",
    "for ekey in exptdata.exptdict.keys():\n",
    "    expt = exptdata.exptdict[ekey]['expt']\n",
    "    n_files = exptdata.exptdict[ekey]['n_files']\n",
    "    time_units = exptdata.exptdict[ekey]['time_units']\n",
    "    offset = exptdata.exptdict[ekey]['offset']\n",
    "    print(expt)\n",
    "    \n",
    "    psi = cc.get_nc_variable(expt, 'ocean.nc', 'ty_trans_rho',\n",
    "                          chunks={'potrho': None},n=n_files,\n",
    "                          time_units = time_units, offset=offset)\n",
    "    psi = psi.sel(grid_xt_ocean=slice(-103,-5)).sum('grid_xt_ocean').sel(method='Nearest',grid_yu_ocean=26)*1.0e-9\n",
    "    psi_sum = psi.cumsum('potrho') - psi.sum('potrho')\n",
    "    \n",
    "    ## If GM overturning is output, load that too\n",
    "    varlist = cc.get_variables(expt, 'ocean.nc')\n",
    "    if 'ty_trans_rho_gm' in varlist:\n",
    "        psiGM = cc.get_nc_variable(expt, 'ocean.nc', 'ty_trans_rho_gm',\n",
    "                              chunks={'potrho': None},n=n_files,\n",
    "                            time_units = time_units, offset=offset)\n",
    "        psiGM = psiGM.sel(grid_xt_ocean=slice(-103,-5)).sum('grid_xt_ocean').sel(method='Nearest',grid_yu_ocean=26)*1.0e-9\n",
    "        psi_sum = psi_sum + psiGM\n",
    "\n",
    "    psi_amoc = psi_sum.sel(potrho=slice(1035.5,None))\\\n",
    "                .max('potrho').resample(time='A').mean('time')\n",
    "    psi_amoc.plot(label=exptdata.exptdict[ekey]['desc'])\n",
    "    \n",
    "plt.gca().autoscale()\n",
    "plt.legend()\n",
    "plt.xlabel('Year')\n",
    "plt.xlim([pd.datetime(1958,1,1),pd.datetime(2017,12,31)])\n",
    "plt.ylabel('Overturning (Sv)')\n",
    "plt.title('(a) AMOC at 26°N')\n",
    "\n",
    "savefigure('overturning_timeseries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-18.04]",
   "language": "python",
   "name": "conda-env-analysis3-18.04-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
