{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sea ice timeseries for ACCESS-OM2_01\n",
    "TODO: compare thickness with cryosat data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available exptdata keys:  ['1deg', '025deg', '01deg']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import cosima_cookbook as cc\n",
    "from dask.distributed import Client\n",
    "from glob import glob\n",
    "import os,sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "from tqdm import tqdm_notebook\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from calendar import month_abbr\n",
    "import cmocean as cm\n",
    "import pandas as pd\n",
    "import calendar\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import copy\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))  # so we can import ../exptdata\n",
    "import exptdata\n",
    "print('Available exptdata keys: ', [k for k in exptdata.exptdict.keys()])\n",
    "\n",
    "# set up time units and offset to suit CICE \n",
    "# see https://github.com/OceansAus/ACCESS-OM2-1-025-010deg-report/commit/ce3b6331bc4f304d2c5f957ccd2a0ae9ca5d6970#commitcomment-31646163\n",
    "# for e in exptdata.exptdict.keys():\n",
    "#     exptdata.exptdict[e]['time_units'] = None\n",
    "\n",
    "# Set up time_units to suit CICE \n",
    "# Only retain netcdf time_units for 0.1 deg.\n",
    "# We need to change time_units of 1deg and 0.25 deg \n",
    "# to shift the time so the last cycle starts in 1958.\n",
    "# But we don't need offset because CICE time starts at beginning of run, \n",
    "# unlike MOM which starts in year 0001.\n",
    "exptdata.exptdict['01deg']['time_units'] = \"days since 1985-01-01\"  # don't use None - it leaves the time as cftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To deal with memory issues:\n",
    "* In a terminal on VDI (either over VNC or through SSH and inside screen/tmux), run:\n",
    "`dask-scheduler`\n",
    "* This should output the scheduler address, like `tcp://10.0.64.11:8786`. \n",
    "* Now, in another terminal (ensuring that the default conda module has cosima_cookbook installed, as all workers will need access to that), run:\n",
    "`dask-worker tcp://10.0.64.11:8786 --memory-limit 4e9 --nprocs 6 --nthreads 1 --local-directory /local/g40/aek156`\n",
    "* Then, make sure the following cell matches the scheduler address."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "client=Client('tcp://10.0.64.11:8786', local_dir='/local/g40/aek156')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc.start_cluster()  # use Client instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('1deg',\n",
       "              {'model': 'access-om2',\n",
       "               'expt': '1deg_jra55v13_iaf_spinup1_B1',\n",
       "               'desc': 'ACCESS-OM2',\n",
       "               'n_files': -12,\n",
       "               'time_units': 'days since 1718-01-01',\n",
       "               'offset': -87658,\n",
       "               'exptdir': '/g/data3/hh5/tmp/cosima/access-om2/1deg_jra55v13_iaf_spinup1_B1_lastcycle'}),\n",
       "             ('025deg',\n",
       "              {'model': 'access-om2-025',\n",
       "               'expt': '025deg_jra55v13_iaf_gmredi6',\n",
       "               'desc': 'ACCESS-OM2-025',\n",
       "               'n_files': -34,\n",
       "               'time_units': 'days since 1718-01-01',\n",
       "               'offset': -87658,\n",
       "               'exptdir': '/g/data3/hh5/tmp/cosima/access-om2-025/025deg_jra55v13_iaf_gmredi6'}),\n",
       "             ('01deg',\n",
       "              {'model': 'access-om2-01',\n",
       "               'expt': '01deg_jra55v13_iaf',\n",
       "               'desc': 'ACCESS-OM2-01',\n",
       "               'n_files': None,\n",
       "               'time_units': 'days since 1985-01-01',\n",
       "               'offset': None,\n",
       "               'exptdir': '/g/data3/hh5/tmp/cosima/access-om2-01/01deg_jra55v13_iaf'})])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exptdata.exptdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc.build_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "figdir = ''\n",
    "# NOSYNC = '/g/data/v45/aek156/figures/ACCESS-OM2-1-025-010deg-report/figures/ice_validation/NOSYNC/' # where to save figs we don't want to sync\n",
    "NOSYNC = 'NOSYNC/' # where to save figs we don't want to sync\n",
    "if not os.path.exists(NOSYNC):\n",
    "    os.makedirs(NOSYNC)\n",
    "def savefigure(fname):\n",
    "    plt.savefig(os.path.join(figdir, fname+'.png'),dpi=300, bbox_inches=\"tight\")  # comment out to disable saving\n",
    "    plt.savefig(os.path.join(figdir, fname+'.pdf'),dpi=300, bbox_inches=\"tight\")  # comment out to disable saving\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixcicetime(da):\n",
    "    '''\n",
    "    Correct the time coordinate in DataArray from CICE netcdf file.\n",
    "    \n",
    "    CICE netcdf files unhelpfully have a time coordinate which is just after the end of the averaging period, \n",
    "    e.g. the time stamp for a January average is 1 February, which messes up groupby month etc.\n",
    "    \n",
    "    This function just subtracts 12 hours to put it in the correct month (and day, for daily means).\n",
    "    \n",
    "    PR 109 gives an option to fix this:\n",
    "    https://github.com/OceansAus/cosima-cookbook/pull/109\n",
    "    \n",
    "    '''\n",
    "    try:\n",
    "        da['time'] = da.time - np.timedelta64(12, 'h')\n",
    "    except:\n",
    "        da['time'] = da.time - timedelta(hours=12)  # for 01deg which for some reason uses cftime\n",
    "    return da\n",
    "\n",
    "# use this for DataSet: replaces the bad time dimension with the average of time_bounds.\n",
    "#     The time type is also changed to datetime64[ns]\n",
    "#     ds['time'] = ds.time_bounds.astype('int64').mean(axis=1).astype('datetime64[ns]')\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TESTING CICE DATES\n",
    "use_cache=True\n",
    "for ekey in exptdata.exptdict.keys():\n",
    "    print(ekey)\n",
    "#     ekey = '01deg'\n",
    "#     vvv = cc.get_nc_variable(exptdata.exptdict[ekey]['expt'], 'iceh.????-??.nc', 'vicen_m', time_units=exptdata.exptdict[ekey]['time_units'], use_cache=use_cache, n=-500)\n",
    "    vvv = cc.get_nc_variable(exptdata.exptdict[ekey]['expt'], 'iceh.????-??.nc', 'vicen_m', time_units=None, use_cache=use_cache)\n",
    "    # vvv = cc.get_nc_variable(exptdata.exptdict[ekey]['expt'], 'iceh.????-??.nc', 'vicen_m', time_units='days since 1985-01-01', use_cache=use_cache, n=-500)\n",
    "    print(vvv['time'].data[0])\n",
    "    print(vvv['time'].data[-1])\n",
    "    vvv = cc.get_nc_variable(exptdata.exptdict[ekey]['expt'], 'iceh.????-??.nc', 'vicen_m', time_units=exptdata.exptdict[ekey]['time_units'], use_cache=use_cache)\n",
    "    # vvv = cc.get_nc_variable(exptdata.exptdict[ekey]['expt'], 'iceh.????-??.nc', 'vicen_m', time_units='days since 1985-01-01', use_cache=use_cache, n=-500)\n",
    "    print(vvv['time'].data[0])\n",
    "    print(vvv['time'].data[-1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TESTING MOM DATES\n",
    "use_cache=True\n",
    "for ekey in exptdata.exptdict.keys():\n",
    "    print(ekey)\n",
    "    vvv = cc.get_nc_variable(exptdata.exptdict[ekey]['expt'], 'ocean_month.nc', 'eta_t', time_units=None, use_cache=use_cache)\n",
    "    print(vvv['time'].data[0])\n",
    "    print(vvv['time'].data[-1])\n",
    "\n",
    "    vvv = cc.get_nc_variable(exptdata.exptdict[ekey]['expt'], 'ocean_month.nc', 'eta_t', time_units=None, use_cache=use_cache, offset=0)\n",
    "    print(vvv['time'].data[0])\n",
    "    print(vvv['time'].data[-1])\n",
    "\n",
    "    vvv = cc.get_nc_variable(exptdata.exptdict[ekey]['expt'], 'ocean_month.nc', 'eta_t', time_units=exptdata.exptdict[ekey]['time_units'], use_cache=use_cache)\n",
    "    print(vvv['time'].data[0])\n",
    "    print(vvv['time'].data[-1])\n",
    "    vvv = cc.get_nc_variable(exptdata.exptdict[ekey]['expt'], 'ocean_month.nc', 'eta_t', time_units=exptdata.exptdict[ekey]['time_units'], use_cache=use_cache, offset=exptdata.exptdict[ekey]['offset'])\n",
    "    print(vvv['time'].data[0])\n",
    "    print(vvv['time'].data[-1])\n",
    "    vvv = cc.get_nc_variable(exptdata.exptdict[ekey]['expt'], 'ocean_month.nc', 'eta_t', time_units=exptdata.exptdict[ekey]['time_units'], use_cache=use_cache, offset=0)\n",
    "    print(vvv['time'].data[0])\n",
    "    print(vvv['time'].data[-1])\n",
    "    vvv = cc.get_nc_variable(exptdata.exptdict[ekey]['expt'], 'ocean_month.nc', 'eta_t', time_units=None, use_cache=use_cache, offset=exptdata.exptdict[ekey]['offset'])\n",
    "    print(vvv['time'].data[0])\n",
    "    print(vvv['time'].data[-1])\n",
    "    vvv = cc.get_nc_variable(exptdata.exptdict[ekey]['expt'], 'ocean_month.nc', 'eta_t', time_units='days since 1618-01-01', use_cache=use_cache, offset=exptdata.exptdict[ekey]['offset'])\n",
    "    print(vvv['time'].data[0])\n",
    "    print(vvv['time'].data[-1])\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size':13}\n",
    "tick_font=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc.build_index(careful=True)\n",
    "# cc.build_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use common start and end dates for all runs\n",
    "tstart = exptdata.clim_tstart\n",
    "tend = exptdata.clim_tend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1993-2017\n",
      "tstart =  1993-01-01 00:00:00\n",
      "tend =  2018-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "firstyear = pd.to_datetime(tstart).year  # assumes tstart is 1 January!\n",
    "lastyear = pd.to_datetime(tend).year-1  # assumes tend is 1 January!\n",
    "yearrange = str(firstyear)+'-'+str(lastyear)\n",
    "print(yearrange)\n",
    "print('tstart = ', tstart)\n",
    "print('tend = ', tend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify paths to observational data\n",
    "\n",
    "ObsDirExt = '/g/data3/hh5/tmp/cosima/observations/NOAA/G02135'  # from http://nsidc.org/data/g02135\n",
    "obsExtNHFileList = glob(os.path.join(ObsDirExt, 'north/monthly/data/*.csv'))\n",
    "obsExtSHFileList = glob(os.path.join(ObsDirExt, 'south/monthly/data/*.csv'))\n",
    "obsExtNHFileList.sort()\n",
    "obsExtSHFileList.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddata(ekey, varnames = ['aice_m', 'hi_m', 'hs_m', 'vicen_m']):\n",
    "#   NB: varnames must be t-grid variables\n",
    "    global ice_data\n",
    "    try:\n",
    "        ice_data\n",
    "    except NameError:\n",
    "        ice_data = copy.deepcopy(exptdata.exptdict)  # to store ice fields under the same keys as exptdata.exptdict\n",
    "    ide = ice_data[ekey]\n",
    "    expt = ide['expt']\n",
    "    exptdir = ide['exptdir']\n",
    "    time_units = ide['time_units']\n",
    "    \n",
    "    if 'area_t' not in ide.keys():\n",
    "        # get model grid data from MOM outputs since CICE ones have nans on land\n",
    "        gridFileList = glob(os.path.join(exptdir, 'output*/ocean/ocean_grid.nc'))\n",
    "        gridFileList.sort()\n",
    "        gridfile = xr.open_dataset(gridFileList[0])\n",
    "        ide['xt_ocean'] = gridfile.xt_ocean.values\n",
    "        ide['yt_ocean'] = gridfile.yt_ocean.values\n",
    "\n",
    "        varname = 'area_t'\n",
    "        var = gridfile[varname]\n",
    "        ide[varname] = var\n",
    "        ide[varname+'_NH'] = var.sel(yt_ocean=slice(0, 90))\n",
    "        ide[varname+'_SH'] = var.sel(yt_ocean=slice(-90,0))\n",
    "\n",
    "        varname = 'lon_t'\n",
    "        var = exptdata.joinseams(gridfile.geolon_t, tripole_flip=True, lon=True)\n",
    "        ide[varname] = var\n",
    "        ide[varname+'_NH'] = var.sel(yt_ocean=slice(0, 90))\n",
    "        ide[varname+'_SH'] = var.sel(yt_ocean=slice(-90,0))\n",
    "\n",
    "        varname = 'lat_t'\n",
    "        var = exptdata.joinseams(gridfile.geolat_t, tripole_flip=True)\n",
    "        ide[varname] = var\n",
    "        ide[varname+'_NH'] = var.sel(yt_ocean=slice(0, 90))\n",
    "        ide[varname+'_SH'] = var.sel(yt_ocean=slice(-90,0))\n",
    "\n",
    "    for varname in varnames:\n",
    "        print(varname)\n",
    "        if varname not in ide.keys():\n",
    "            if ekey=='01deg':\n",
    "                # work around bug: https://github.com/OceansAus/cosima-cookbook/issues/118\n",
    "                nfiles = len(glob(os.path.join(exptdir, 'output*/ice/OUTPUT/iceh.????-??.nc')))\n",
    "                tmp1 = cc.get_nc_variable(expt, 'iceh.????-??.nc', varname, time_units=time_units, \n",
    "                                     use_cache=use_cache, n=nfiles-200)\n",
    "                tmp2 = cc.get_nc_variable(expt, 'iceh.????-??.nc', varname, time_units=time_units, \n",
    "                                     use_cache=use_cache, n=-200)\n",
    "                var = fixcicetime(xr.concat([tmp1, tmp2], dim='time'))\n",
    "            else:\n",
    "                var = fixcicetime(cc.get_nc_variable(expt, 'iceh.????-??.nc', varname, time_units=time_units, \n",
    "                                     use_cache=use_cache, n=-500))\n",
    "            # use physical coords instead of indices - ASSUMES VARIABLES ARE ON T GRID!\n",
    "            var.coords['ni'] = ide['xt_ocean']\n",
    "            var.coords['nj'] = ide['yt_ocean']\n",
    "            var = var.rename(({'ni':'xt_ocean', 'nj':'yt_ocean'}))\n",
    "            ide[varname] = var\n",
    "            ide[varname+'_NH'] = var.sel(yt_ocean=slice(0, 90))\n",
    "            ide[varname+'_SH'] = var.sel(yt_ocean=slice(-90,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series of sea ice volume (by category), area, extent and snow volume\n",
    "\n",
    "`vicen_m(time, nc, nj, ni)`\n",
    "\t\thas units = \"m\",\n",
    "so need to multiply by `area_t` to get volume.\n",
    "`nc` is number of ice categories.\n",
    "\n",
    "We use kcatbound=0, so lower bound of ice categories is 0, 0.64, 1.39, 2.47, 4.57m (HunkeLipscombTurnerJefferyElliott2015a-CICE5p1, table 2).\n",
    "\n",
    "Much of the Arctic ice volume (not area) is >4.57m thick, including in the summer minimum.\n",
    "\n",
    "<font color=\"FF0000\"><B>FIXME:<B> land mask area differs between the three configurations and differs from obs, especially in the Canadian Archipelago and River Ob - how to remove this bias in the total extent, area and volume? Can we at least quantify the area differences poleward of (say) 65N/S?\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcvol(ekey):\n",
    "# WARNING - this can take several minutes\n",
    "    global ice_data\n",
    "    ide = ice_data[ekey]\n",
    "    if 'NH_ice_volume' not in ide.keys():\n",
    "        volume = ide['vicen_m']*ide['area_t'] # vicen_m(time, nc, nj, ni) has units = \"m\", so need to multiply by `area_t` to get volume.\n",
    "        volume_zonalsum = volume.sum('xt_ocean').compute()  # do this once for both NH & SH\n",
    "        ide['NH_ice_volume'] = volume_zonalsum.sel(yt_ocean=slice(0, 90)).sum('yt_ocean')\n",
    "        ide['SH_ice_volume'] = volume_zonalsum.sel(yt_ocean=slice(-90,0)).sum('yt_ocean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotvol(v):\n",
    "    v = v.sel(time=slice(pd.to_datetime('1985', format='%Y'),tend))  # common time range for all plots\n",
    "    for c in range(len(v['nc'])):\n",
    "        plt.plot(v['time'],v.isel(nc=c)/1e12, color='C'+str(c), linewidth=1, label='Category '+str(c+1))\n",
    "        plt.plot(v['time'],\n",
    "                 v.rolling(time=12, center=True).mean().isel(nc=c)/1e12, # 12-month rolling mean\n",
    "                 color='C'+str(c), linewidth=2)\n",
    "#     total\n",
    "#     plt.plot(v['time'],v.sum(axis=-1)/1e12, color='k', linewidth=1, label='Total')\n",
    "#     plt.plot(v['time'][6:-5],\n",
    "#              v.rolling(time=12, center=True).mean().sum(axis=-1)[6:-5]/1e12,  # 12-month rolling mean\n",
    "#              color='k', linewidth=2)\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.xlabel('Year',font)\n",
    "    plt.ylabel(r'Ice volume (10$^{12}$ m$^3$)',font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotvolcumul(v):\n",
    "    v = v.sel(time=slice(pd.to_datetime('1985', format='%Y'),tend))  # common time range for all plots\n",
    "    v = v.cumsum(axis=-1)\n",
    "    cats = list(range(len(v['nc'])))\n",
    "    cats.reverse()  # so legend is in same order as plotted data\n",
    "    for c in cats:\n",
    "        plt.plot(v['time'],v.isel(nc=c)/1e12, color='C'+str(c), linewidth=1, label='Category '+'+'.join([str(f+1) for f in range(c+1)]))\n",
    "        plt.plot(v['time'],\n",
    "                 v.rolling(time=12, center=True).mean().isel(nc=c)/1e12, # 12-month rolling mean\n",
    "                 color='C'+str(c), linewidth=2)\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.xlabel('Year',font)\n",
    "    plt.ylabel(r'Ice volume (10$^{12}$ m$^3$)',font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotvolNHSH():\n",
    "    plt.figure(1,(12,5))\n",
    "    plt.clf()\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "    plotvol(NH_ice_volume)\n",
    "    plt.title('Arctic ice volume, '+exptdata.exptdict[ekey]['desc'],font)\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plotvol(SH_ice_volume)\n",
    "    plt.title('Antarctic ice volume, '+exptdata.exptdict[ekey]['desc'],font)\n",
    "    plt.legend(prop=font,loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    savefigure('ice_volume_categories_'+ekey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotvolcumulNHSH():\n",
    "    plt.figure(1,(12,5))\n",
    "    plt.clf()\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "    plotvolcumul(NH_ice_volume)\n",
    "    plt.title('Arctic ice volume, '+exptdata.exptdict[ekey]['desc'],font)\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plotvolcumul(SH_ice_volume)\n",
    "    plt.title('Antarctic ice volume, '+exptdata.exptdict[ekey]['desc'],font)\n",
    "    plt.legend(prop=font,loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    savefigure('ice_volume_categories_cumulative'+ekey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal cycle of sea ice extent and area\n",
    "We adopt the usual definition of sea ice extent as the area in which sea ice concentration exceeds 15\\%.\n",
    "\n",
    "- obs in `/g/data3/hh5/tmp/cosima/observations/NOAA/G02135/north/monthly/data/*.csv` and  `/g/data3/hh5/tmp/cosima/observations/NOAA/G02135/south/monthly/data/*.csv`\n",
    "- file names `N_mm_extent_v3.0.csv`, `S_mm_extent_v3.0.csv` where `mm` is month number\n",
    "- first full year: 1979\n",
    "- last full year: 2017\n",
    "- missing extent data (-9999): Dec 1987, Jan 1988\n",
    "\n",
    "CSV format:\n",
    "```\n",
    "year, mo,    data-type, region, extent,   area\n",
    "1978, 12,      Goddard,      N,  13.67,  10.90\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadObsExt(fnlist):\n",
    "    \"\"\"\n",
    "    Return xarray DataSet of sea ice extent and area from NOAA/G02135 csv file list\n",
    "    \"\"\"\n",
    "    df = pd.concat([pd.read_csv(f) for f in fnlist])  # read all csv files into a pandas DataFrame\n",
    "    df.columns = df.columns.str.strip()  # remove leading/trailing whitespace from headers\n",
    "    df['time'] = df.apply(lambda r: datetime(r['year'], r['mo'], 1), axis=1)  # make a date column (set day=1 to match cice output)\n",
    "    print(df)\n",
    "    df = df.drop(columns=['year', 'mo', 'data-type', 'region'])  # remove redundant columns\n",
    "    num = df._get_numeric_data()\n",
    "    num[num < 0] = np.nan  # replace bad data with NaN\n",
    "    df = df.sort_values('time')\n",
    "    ds = df.to_xarray()  # convert to xarray DataSet\n",
    "    ds = ds.assign_coords(index=ds['time']).drop('time')  # set index values to time and remove time\n",
    "    ds['extent'] = ds.extent.rename({'index': 'time'})  # rename extent coord to time\n",
    "    ds['area'] = ds.area.rename({'index': 'time'})  # rename area coord to time\n",
    "    ds = ds.drop('index')  # remove index\n",
    "    ds = ds*1e12  # convert from M km^2 to m^2\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  mo      data-type   region   extent     area       time\n",
      "0   1979   1        Goddard        N    15.41    12.41 1979-01-01\n",
      "1   1980   1        Goddard        N    14.86    11.94 1980-01-01\n",
      "2   1981   1        Goddard        N    14.91    11.91 1981-01-01\n",
      "3   1982   1        Goddard        N    15.18    12.19 1982-01-01\n",
      "4   1983   1        Goddard        N    14.94    12.01 1983-01-01\n",
      "5   1984   1        Goddard        N    14.47    11.68 1984-01-01\n",
      "6   1985   1        Goddard        N    14.72    11.69 1985-01-01\n",
      "7   1986   1        Goddard        N    14.89    11.88 1986-01-01\n",
      "8   1987   1        Goddard        N    14.97    11.90 1987-01-01\n",
      "9   1988   1          -9999        N -9999.00 -9999.00 1988-01-01\n",
      "10  1989   1        Goddard        N    14.95    13.18 1989-01-01\n",
      "11  1990   1        Goddard        N    14.78    12.80 1990-01-01\n",
      "12  1991   1        Goddard        N    14.36    12.57 1991-01-01\n",
      "13  1992   1        Goddard        N    14.64    12.61 1992-01-01\n",
      "14  1993   1        Goddard        N    14.90    12.93 1993-01-01\n",
      "15  1994   1        Goddard        N    14.73    12.88 1994-01-01\n",
      "16  1995   1        Goddard        N    14.59    12.79 1995-01-01\n",
      "17  1996   1        Goddard        N    14.18    12.15 1996-01-01\n",
      "18  1997   1        Goddard        N    14.42    12.39 1997-01-01\n",
      "19  1998   1        Goddard        N    14.72    12.81 1998-01-01\n",
      "20  1999   1        Goddard        N    14.36    12.60 1999-01-01\n",
      "21  2000   1        Goddard        N    14.22    12.30 2000-01-01\n",
      "22  2001   1        Goddard        N    14.20    12.35 2001-01-01\n",
      "23  2002   1        Goddard        N    14.27    12.26 2002-01-01\n",
      "24  2003   1        Goddard        N    14.39    12.29 2003-01-01\n",
      "25  2004   1        Goddard        N    14.03    12.26 2004-01-01\n",
      "26  2005   1        Goddard        N    13.66    11.92 2005-01-01\n",
      "27  2006   1        Goddard        N    13.47    11.65 2006-01-01\n",
      "28  2007   1        Goddard        N    13.70    11.86 2007-01-01\n",
      "29  2008   1        Goddard        N    13.89    12.30 2008-01-01\n",
      "..   ...  ..            ...      ...      ...      ...        ...\n",
      "10  1988  12        Goddard        N    13.63    11.99 1988-12-01\n",
      "11  1989  12        Goddard        N    13.39    11.61 1989-12-01\n",
      "12  1990  12        Goddard        N    13.11    11.47 1990-12-01\n",
      "13  1991  12        Goddard        N    12.95    11.19 1991-12-01\n",
      "14  1992  12        Goddard        N    13.41    11.72 1992-12-01\n",
      "15  1993  12        Goddard        N    13.32    11.48 1993-12-01\n",
      "16  1994  12        Goddard        N    13.27    11.49 1994-12-01\n",
      "17  1995  12        Goddard        N    12.92    11.09 1995-12-01\n",
      "18  1996  12        Goddard        N    12.86    11.03 1996-12-01\n",
      "19  1997  12        Goddard        N    13.08    11.24 1997-12-01\n",
      "20  1998  12        Goddard        N    12.76    10.91 1998-12-01\n",
      "21  1999  12        Goddard        N    12.64    10.99 1999-12-01\n",
      "22  2000  12        Goddard        N    12.64    10.96 2000-12-01\n",
      "23  2001  12        Goddard        N    12.49    10.55 2001-12-01\n",
      "24  2002  12        Goddard        N    12.61    10.64 2002-12-01\n",
      "25  2003  12        Goddard        N    12.59    10.80 2003-12-01\n",
      "26  2004  12        Goddard        N    12.55    10.98 2004-12-01\n",
      "27  2005  12        Goddard        N    12.23    10.56 2005-12-01\n",
      "28  2006  12        Goddard        N    11.95    10.17 2006-12-01\n",
      "29  2007  12        Goddard        N    12.03    10.18 2007-12-01\n",
      "30  2008  12        Goddard        N    12.36    10.97 2008-12-01\n",
      "31  2009  12        Goddard        N    12.20    10.59 2009-12-01\n",
      "32  2010  12        Goddard        N    11.83    10.43 2010-12-01\n",
      "33  2011  12        Goddard        N    12.15    10.63 2011-12-01\n",
      "34  2012  12        Goddard        N    12.01    10.45 2012-12-01\n",
      "35  2013  12        Goddard        N    12.18    10.87 2013-12-01\n",
      "36  2014  12        Goddard        N    12.35    10.89 2014-12-01\n",
      "37  2015  12        Goddard        N    12.04    10.64 2015-12-01\n",
      "38  2016  12        NRTSI-G        N    11.47     9.59 2016-12-01\n",
      "39  2017  12        NRTSI-G        N    11.75    10.22 2017-12-01\n",
      "\n",
      "[472 rows x 7 columns]\n",
      "    year  mo      data-type   region   extent     area       time\n",
      "0   1979   1        Goddard        S     5.40     3.47 1979-01-01\n",
      "1   1980   1        Goddard        S     4.56     3.08 1980-01-01\n",
      "2   1981   1        Goddard        S     4.41     2.84 1981-01-01\n",
      "3   1982   1        Goddard        S     5.26     3.25 1982-01-01\n",
      "4   1983   1        Goddard        S     4.77     3.21 1983-01-01\n",
      "5   1984   1        Goddard        S     4.78     2.93 1984-01-01\n",
      "6   1985   1        Goddard        S     4.46     2.87 1985-01-01\n",
      "7   1986   1        Goddard        S     5.42     3.43 1986-01-01\n",
      "8   1987   1        Goddard        S     5.13     3.31 1987-01-01\n",
      "9   1988   1          -9999        S -9999.00 -9999.00 1988-01-01\n",
      "10  1989   1        Goddard        S     4.74     3.17 1989-01-01\n",
      "11  1990   1        Goddard        S     4.87     3.39 1990-01-01\n",
      "12  1991   1        Goddard        S     5.34     3.52 1991-01-01\n",
      "13  1992   1        Goddard        S     4.75     3.24 1992-01-01\n",
      "14  1993   1        Goddard        S     4.41     2.55 1993-01-01\n",
      "15  1994   1        Goddard        S     4.97     3.37 1994-01-01\n",
      "16  1995   1        Goddard        S     5.64     3.73 1995-01-01\n",
      "17  1996   1        Goddard        S     5.87     3.55 1996-01-01\n",
      "18  1997   1        Goddard        S     4.20     2.77 1997-01-01\n",
      "19  1998   1        Goddard        S     4.46     3.04 1998-01-01\n",
      "20  1999   1        Goddard        S     4.82     3.11 1999-01-01\n",
      "21  2000   1        Goddard        S     4.75     2.92 2000-01-01\n",
      "22  2001   1        Goddard        S     5.23     3.64 2001-01-01\n",
      "23  2002   1        Goddard        S     4.74     2.95 2002-01-01\n",
      "24  2003   1        Goddard        S     5.77     4.11 2003-01-01\n",
      "25  2004   1        Goddard        S     5.59     3.80 2004-01-01\n",
      "26  2005   1        Goddard        S     4.75     3.18 2005-01-01\n",
      "27  2006   1        Goddard        S     4.16     2.81 2006-01-01\n",
      "28  2007   1        Goddard        S     4.67     3.00 2007-01-01\n",
      "29  2008   1        Goddard        S     6.41     4.07 2008-01-01\n",
      "..   ...  ..            ...      ...      ...      ...        ...\n",
      "10  1988  12        Goddard        S    11.06     7.40 1988-12-01\n",
      "11  1989  12        Goddard        S     9.84     6.70 1989-12-01\n",
      "12  1990  12        Goddard        S     9.95     6.73 1990-12-01\n",
      "13  1991  12        Goddard        S    10.19     6.80 1991-12-01\n",
      "14  1992  12        Goddard        S    10.21     6.18 1992-12-01\n",
      "15  1993  12        Goddard        S     9.93     6.67 1993-12-01\n",
      "16  1994  12        Goddard        S    10.10     7.11 1994-12-01\n",
      "17  1995  12        Goddard        S    10.62     7.19 1995-12-01\n",
      "18  1996  12        Goddard        S     9.65     6.24 1996-12-01\n",
      "19  1997  12        Goddard        S    10.29     6.99 1997-12-01\n",
      "20  1998  12        Goddard        S    10.52     6.80 1998-12-01\n",
      "21  1999  12        Goddard        S    10.72     6.80 1999-12-01\n",
      "22  2000  12        Goddard        S     9.91     6.95 2000-12-01\n",
      "23  2001  12        Goddard        S    10.35     6.36 2001-12-01\n",
      "24  2002  12        Goddard        S    10.79     7.61 2002-12-01\n",
      "25  2003  12        Goddard        S    10.56     7.20 2003-12-01\n",
      "26  2004  12        Goddard        S    10.23     6.93 2004-12-01\n",
      "27  2005  12        Goddard        S     9.68     6.33 2005-12-01\n",
      "28  2006  12        Goddard        S     9.85     6.48 2006-12-01\n",
      "29  2007  12        Goddard        S    11.98     8.38 2007-12-01\n",
      "30  2008  12        Goddard        S    11.51     7.39 2008-12-01\n",
      "31  2009  12        Goddard        S    10.74     7.09 2009-12-01\n",
      "32  2010  12        Goddard        S    11.27     6.94 2010-12-01\n",
      "33  2011  12        Goddard        S    11.20     7.40 2011-12-01\n",
      "34  2012  12        Goddard        S    10.39     7.38 2012-12-01\n",
      "35  2013  12        Goddard        S    11.85     8.34 2013-12-01\n",
      "36  2014  12        Goddard        S    11.93     8.21 2014-12-01\n",
      "37  2015  12        Goddard        S    10.66     7.09 2015-12-01\n",
      "38  2016  12        NRTSI-G        S     8.18     5.44 2016-12-01\n",
      "39  2017  12        NRTSI-G        S     9.34     6.13 2017-12-01\n",
      "\n",
      "[472 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "NH_obs = loadObsExt(obsExtNHFileList)\n",
    "NH_clim_obs = NH_obs.sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)\n",
    "# NH_extent_clim_obs = NH_climatology_obs.extent\n",
    "SH_obs = loadObsExt(obsExtSHFileList)\n",
    "SH_clim_obs = SH_obs.sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)\n",
    "# SH_extent_clim_obs = SH_climatology_obs.extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcarea(ekey):\n",
    "    global ice_data\n",
    "    ide = ice_data[ekey]\n",
    "    if 'NH_area' not in ide.keys():\n",
    "        area = ide['aice_m']*ide['area_t']\n",
    "        area_zonalsum = area.sum('xt_ocean').compute()  # do this once for both NH & SH\n",
    "        ide['NH_area'] = area_zonalsum.sel(yt_ocean=slice(0, 90)).sum('yt_ocean')\n",
    "        ide['SH_area'] = area_zonalsum.sel(yt_ocean=slice(-90,0)).sum('yt_ocean')\n",
    "        ide['NH_area_clim'] = ide['NH_area'].sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)\n",
    "        ide['SH_area_clim'] = ide['SH_area'].sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcextent(ekey):\n",
    "    global ice_data\n",
    "    ide = ice_data[ekey]\n",
    "    if 'NH_extent' not in ide.keys():\n",
    "        extent = xr.where(ide['aice_m'] > 0.15, ide['area_t'], 0)\n",
    "        extent_zonalsum = extent.sum('xt_ocean').compute()  # do this once for both NH & SH\n",
    "        ide['NH_extent'] = extent_zonalsum.sel(yt_ocean=slice(0, 90)).sum('yt_ocean')\n",
    "        ide['SH_extent'] = extent_zonalsum.sel(yt_ocean=slice(-90,0)).sum('yt_ocean')\n",
    "        ide['NH_extent_clim'] = ide['NH_extent'].sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)\n",
    "        ide['SH_extent_clim'] = ide['SH_extent'].sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotarea(v, obs):\n",
    "    v = v.sel(time=slice(pd.to_datetime('1985', format='%Y'),tend))  # common time range for all plots\n",
    "    plt.plot(v['time'],v/1e12, color='r', linewidth=1, label='Model')\n",
    "    plt.plot(v['time'],\n",
    "             v.rolling(time=12, center=True).mean()/1e12, # 12-month rolling mean\n",
    "             color='r', linewidth=2)\n",
    "\n",
    "    obs = obs.sel(time=slice(pd.to_datetime('1985', format='%Y'),tend))  # common time range for all plots\n",
    "    plt.plot(obs['time'],obs/1e12, color='k', linewidth=1, label='Obs')\n",
    "    plt.plot(obs['time'],\n",
    "             obs.rolling(time=12, center=True).mean()/1e12, # 12-month rolling mean\n",
    "             color='k', linewidth=2)\n",
    "\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.xlabel('Year',font)\n",
    "    plt.ylabel(r'Ice area (10$^{12}$ m$^2$)',font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotareaNHSH():\n",
    "    plt.figure(1,(12,5))\n",
    "    plt.clf()\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "    plotarea(NH_area, NH_obs.area)\n",
    "    plt.title('Arctic ice area, '+exptdata.exptdict[ekey]['desc'],font)\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plotarea(SH_area, SH_obs.area)\n",
    "    plt.title('Antarctic ice area, '+exptdata.exptdict[ekey]['desc'],font)\n",
    "    plt.legend(prop=font,loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    savefigure('ice_area_'+ekey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotextent(v, obs):\n",
    "    v = v.sel(time=slice(pd.to_datetime('1985', format='%Y'),tend))  # common time range for all plots\n",
    "    plt.plot(v['time'],v/1e12, color='r', linewidth=1, label='Model')\n",
    "    plt.plot(v['time'],\n",
    "             v.rolling(time=12, center=True).mean()/1e12, # 12-month rolling mean\n",
    "             color='r', linewidth=2)\n",
    "\n",
    "    obs = obs.sel(time=slice(pd.to_datetime('1985', format='%Y'),tend))  # common time range for all plots\n",
    "    plt.plot(obs['time'],obs/1e12, color='k', linewidth=1, label='Obs')\n",
    "    plt.plot(obs['time'],\n",
    "             obs.rolling(time=12, center=True).mean()/1e12, # 12-month rolling mean\n",
    "             color='k', linewidth=2)\n",
    "\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.xlabel('Year',font)\n",
    "    plt.ylabel(r'Ice extent (10$^{12}$ m$^2$)',font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotextentNHSH():\n",
    "    plt.figure(1,(12,5))\n",
    "    plt.clf()\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plotextent(NH_extent, NH_obs.extent)\n",
    "    plt.title('Arctic ice extent, '+exptdata.exptdict[ekey]['desc'],font)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plotextent(SH_extent, SH_obs.extent)\n",
    "    plt.title('Antarctic ice extent, '+exptdata.exptdict[ekey]['desc'],font)\n",
    "    plt.legend(prop=font,loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    savefigure('ice_extent_'+ekey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snow volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcsnowvol(ekey):\n",
    "    global ice_data\n",
    "    ide = ice_data[ekey]\n",
    "    if 'NH_snow_volume' not in ide.keys():\n",
    "        svolume = ide['hs_m']*ide['area_t'] # hs_m(time, nj, ni) has units = \"m\", so need to multiply by `area_t` to get volume.\n",
    "        svolume_zonalsum = svolume.sum('xt_ocean').compute()  # do this once for both NH & SH\n",
    "        ide['NH_snow_volume'] = svolume_zonalsum.sel(yt_ocean=slice(0, 90)).sum('yt_ocean')\n",
    "        ide['SH_snow_volume'] = svolume_zonalsum.sel(yt_ocean=slice(-90,0)).sum('yt_ocean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotsnowvol(v):\n",
    "    v = v.sel(time=slice(pd.to_datetime('1985', format='%Y'),tend))  # common time range for all plots\n",
    "    plt.plot(v['time'],v/1e12, linewidth=1)\n",
    "    plt.plot(v['time'],\n",
    "             v.rolling(time=12, center=True).mean()/1e12, # 12-month rolling mean\n",
    "             linewidth=2)\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.xlabel('Year',font)\n",
    "    plt.ylabel(r'Snow volume (10$^{12}$ m$^3$)',font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotsnowvolNHSH():\n",
    "    plt.figure(1,(12,5))\n",
    "    plt.clf()\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "    plotsnowvol(NH_snow_volume)\n",
    "    plt.title('Arctic snow volume, '+exptdata.exptdict[ekey]['desc'],font)\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plotsnowvol(SH_snow_volume)\n",
    "    plt.title('Antarctic snow volume, '+exptdata.exptdict[ekey]['desc'],font)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    savefigure('snow_volume_'+ekey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make timeseries plots for all resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1deg\n",
      "aice_m\n",
      "hi_m\n",
      "hs_m\n",
      "vicen_m\n",
      "025deg\n",
      "aice_m\n",
      "hi_m\n",
      "hs_m\n",
      "vicen_m\n",
      "01deg\n",
      "aice_m\n",
      "Reading from cache file cache_get_nc_variable_01deg_jra55v13_iaf_iceh.????-??.nc_aice_m_196_days-since-1985-01-01_None_False.pkl\n",
      "Reading from cache file cache_get_nc_variable_01deg_jra55v13_iaf_iceh.????-??.nc_aice_m_-200_days-since-1985-01-01_None_False.pkl\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-850c07056638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mekey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mice_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mekey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloaddata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mekey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mcalcvol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mekey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcalcarea\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mekey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-fd7f63cba574>\u001b[0m in \u001b[0;36mloaddata\u001b[0;34m(ekey, varnames)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 tmp2 = cc.get_nc_variable(expt, 'iceh.????-??.nc', varname, time_units=time_units, \n\u001b[1;32m     48\u001b[0m                                      use_cache=use_cache, n=-200)\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixcicetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 var = fixcicetime(cc.get_nc_variable(expt, 'iceh.????-??.nc', varname, time_units=time_units, \n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-18.10/lib/python3.6/site-packages/xarray/core/combine.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, dim, data_vars, coords, compat, positions, indexers, mode, concat_over)\u001b[0m\n\u001b[1;32m    120\u001b[0m         raise TypeError('can only concatenate xarray Dataset and DataArray '\n\u001b[1;32m    121\u001b[0m                         'objects, got %s' % type(first_obj))\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-18.10/lib/python3.6/site-packages/xarray/core/combine.py\u001b[0m in \u001b[0;36m_dataarray_concat\u001b[0;34m(arrays, dim, data_vars, coords, compat, positions)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     ds = _dataset_concat(datasets, dim, data_vars, coords, compat,\n\u001b[0;32m--> 341\u001b[0;31m                          positions)\n\u001b[0m\u001b[1;32m    342\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_temp_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-18.10/lib/python3.6/site-packages/xarray/core/combine.py\u001b[0m in \u001b[0;36m_dataset_concat\u001b[0;34m(datasets, dim, data_vars, coords, compat, positions)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcat_over\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mvars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_common_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0minsert_result_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-18.10/lib/python3.6/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(variables, dim, positions, shortcut)\u001b[0m\n\u001b[1;32m   1980\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndexVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1982\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-18.10/lib/python3.6/site-packages/xarray/core/variable.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(cls, variables, dim, positions, shortcut)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_axis_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mduck_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1416\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpositions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                 \u001b[0;31m# TODO: deprecate this option -- we don't need it for groupby\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-18.10/lib/python3.6/site-packages/xarray/core/duck_array_ops.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(arrays, axis)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;34m\"\"\"concatenate() with better dtype promotion rules.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_concatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_shared_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-18.10/lib/python3.6/site-packages/xarray/core/duck_array_ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meager_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-18.10/lib/python3.6/site-packages/dask/array/core.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(seq, axis, allow_unknown_chunksizes)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0muc_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munify_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0muc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m     \u001b[0mbds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-18.10/lib/python3.6/site-packages/dask/array/core.py\u001b[0m in \u001b[0;36munify_chunks\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m     arginds = [(asarray(a) if ind is not None else a, ind)\n\u001b[0;32m-> 2539\u001b[0;31m                for a, ind in partition(2, args)]  # [x, ij, y, jk]\n\u001b[0m\u001b[1;32m   2540\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marginds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [(x, ij), (y, jk)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m     \u001b[0mwarn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'warn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-18.10/lib/python3.6/site-packages/dask/array/core.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m     arginds = [(asarray(a) if ind is not None else a, ind)\n\u001b[0;32m-> 2539\u001b[0;31m                for a, ind in partition(2, args)]  # [x, ij, y, jk]\n\u001b[0m\u001b[1;32m   2540\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marginds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [(x, ij), (y, jk)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m     \u001b[0mwarn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'warn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-18.10/lib/python3.6/site-packages/dask/array/core.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, **kwargs)\u001b[0m\n\u001b[1;32m   3058\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3059\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3060\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetter_inline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-18.10/lib/python3.6/site-packages/dask/array/core.py\u001b[0m in \u001b[0;36mfrom_array\u001b[0;34m(x, chunks, name, lock, asarray, fancy, getitem)\u001b[0m\n\u001b[1;32m   2202\u001b[0m     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2205\u001b[0m         \u001b[0moriginal_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'array-original-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'array-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-18.10/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-18.10/lib/python3.6/site-packages/dask/utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \"\"\"\n\u001b[1;32m    412\u001b[0m         \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-18.10/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mnormalize_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_buffer_hex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBufferError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_buffer_hex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ice_data\n",
    "except NameError:\n",
    "    ice_data = copy.deepcopy(exptdata.exptdict)  # to store ice fields under the same keys as exptdata.exptdict\n",
    "for ekey in ice_data.keys():\n",
    "    print(ekey)\n",
    "    loaddata(ekey)\n",
    "    calcvol(ekey)\n",
    "    calcarea(ekey)\n",
    "    calcextent(ekey)\n",
    "    calcsnowvol(ekey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ekey in ice_data.keys():\n",
    "    print(ekey)\n",
    "    print(type(ice_data[ekey]['NH_ice_volume'].time.values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12-mo running mean minimum, mean and maximum of volume for all models\n",
    "plt.figure(1,(12,5))\n",
    "for c, ekey in enumerate(['01deg']):#ice_data.keys()):\n",
    "    plt.subplot(1,2,1)\n",
    "    totvol = ice_data[ekey]['NH_ice_volume'].sum('nc')/1e12\n",
    "    plt.plot(totvol['time'][6:-5],totvol.rolling(time=12, center=True).max()[6:-5], color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "    plt.plot(totvol['time'][6:-5],totvol.rolling(time=12, center=True).mean()[6:-5], color='C'+str(c), linewidth=1)\n",
    "    plt.plot(totvol['time'][6:-5],totvol.rolling(time=12, center=True).min()[6:-5], color='C'+str(c), linewidth=1)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    totvol = ice_data[ekey]['SH_ice_volume'].sum('nc')/1e12\n",
    "    plt.plot(totvol['time'][6:-5],totvol.rolling(time=12, center=True).max()[6:-5], color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "    plt.plot(totvol['time'][6:-5],totvol.rolling(time=12, center=True).mean()[6:-5], color='C'+str(c), linewidth=1)\n",
    "    plt.plot(totvol['time'][6:-5],totvol.rolling(time=12, center=True).min()[6:-5], color='C'+str(c), linewidth=1)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.ylim(ymin=0,ymax=40)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Year',font)\n",
    "plt.ylabel(r'Sea ice volume (10$^{12}$ m$^3$)',font)\n",
    "plt.title('Arctic ice volume minimum, mean and maximum',font)\n",
    "plt.subplot(1,2,2)\n",
    "plt.ylim(ymin=0,ymax=40)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Year',font)\n",
    "plt.ylabel(r'Sea ice volume (10$^{12}$ m$^3$)',font)\n",
    "plt.title('Antarctic ice volume minimum, mean and maximum',font)\n",
    "plt.legend(prop=font,loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "savefigure('ice_volume_min_mean_max_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12-mo running mean minimum, mean and maximum of area for all models\n",
    "plt.figure(1,(12,5))\n",
    "for c, ekey in enumerate(ice_data.keys()):\n",
    "    plt.subplot(1,2,1)\n",
    "    v = ice_data[ekey]['NH_area']/1e12\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).max()[6:-5], color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='C'+str(c), linewidth=1)\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).min()[6:-5], color='C'+str(c), linewidth=1)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    v = ice_data[ekey]['SH_area']/1e12\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).max()[6:-5], color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='C'+str(c), linewidth=1)\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).min()[6:-5], color='C'+str(c), linewidth=1)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "v = NH_obs.area/1e12\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).max()[6:-5], color='k', linewidth=1, label='Observations')\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='k', linewidth=1)\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).min()[6:-5], color='k', linewidth=1)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "v = SH_obs.area/1e12\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).max()[6:-5], color='k', linewidth=1, label='Observations')\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='k', linewidth=1)\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).min()[6:-5], color='k', linewidth=1)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.ylim(ymin=0,ymax=17)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Year',font)\n",
    "plt.ylabel(r'Sea ice area (10$^{12}$ m$^2$)',font)\n",
    "plt.title('Arctic ice area minimum, mean and maximum',font)\n",
    "plt.subplot(1,2,2)\n",
    "plt.ylim(ymin=0,ymax=17)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Year',font)\n",
    "plt.ylabel(r'Sea ice area (10$^{12}$ m$^2$)',font)\n",
    "plt.title('Antarctic ice area minimum, mean and maximum',font)\n",
    "plt.legend(prop=font,loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "savefigure('ice_area_min_mean_max_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12-mo running mean minimum, mean and maximum of extent for all models\n",
    "plt.figure(1,(12,5))\n",
    "for c, ekey in enumerate(ice_data.keys()):\n",
    "    plt.subplot(1,2,1)\n",
    "    v = ice_data[ekey]['NH_extent']/1e12\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).max()[6:-5], color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='C'+str(c), linewidth=1)\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).min()[6:-5], color='C'+str(c), linewidth=1)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    v = ice_data[ekey]['SH_extent']/1e12\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).max()[6:-5], color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='C'+str(c), linewidth=1)\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).min()[6:-5], color='C'+str(c), linewidth=1)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "v = NH_obs.extent/1e12\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).max()[6:-5], color='k', linewidth=1, label='Observations')\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='k', linewidth=1)\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).min()[6:-5], color='k', linewidth=1)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "v = SH_obs.extent/1e12\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).max()[6:-5], color='k', linewidth=1, label='Observations')\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='k', linewidth=1)\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).min()[6:-5], color='k', linewidth=1)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.ylim(ymin=0,ymax=22)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Year',font)\n",
    "plt.ylabel(r'Sea ice extent (10$^{12}$ m$^2$)',font)\n",
    "plt.title('Arctic ice extent minimum, mean and maximum',font)\n",
    "plt.subplot(1,2,2)\n",
    "plt.ylim(ymin=0,ymax=22)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Year',font)\n",
    "plt.ylabel(r'Sea ice extent (10$^{12}$ m$^2$)',font)\n",
    "plt.title('Antarctic ice extent minimum, mean and maximum',font)\n",
    "plt.legend(prop=font,loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "savefigure('ice_extent_min_mean_max_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12-mo running mean and timeseries of area for all models\n",
    "plt.figure(1,(12,5))\n",
    "for c, ekey in enumerate(['01deg']):#ice_data.keys()):\n",
    "    plt.subplot(1,2,1)\n",
    "    v = ice_data[ekey]['NH_area']/1e12\n",
    "    plt.plot(v['time'],v, color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "#     plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='C'+str(c), linewidth=2)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    v = ice_data[ekey]['SH_area']/1e12\n",
    "    plt.plot(v['time'],v, color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "#     plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='C'+str(c), linewidth=2)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "v = NH_obs.area/1e12\n",
    "plt.plot(v['time'],v, color='k', linewidth=1, label='Observations')\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='k', linewidth=1)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "v = SH_obs.area/1e12\n",
    "plt.plot(v['time'],v, color='k', linewidth=1, label='Observations')\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='k', linewidth=1)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.ylim(ymin=0,ymax=17)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Year',font)\n",
    "plt.ylabel(r'Sea ice area (10$^{12}$ m$^2$)',font)\n",
    "plt.title('Arctic sea ice area',font)\n",
    "plt.subplot(1,2,2)\n",
    "plt.ylim(ymin=0,ymax=17)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Year',font)\n",
    "plt.ylabel(r'Sea ice area (10$^{12}$ m$^2$)',font)\n",
    "plt.title('Antarctic sea ice area',font)\n",
    "plt.legend(prop=font,loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "savefigure('ice_area_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12-mo running mean minimum, mean and maximum of snow volume for all models\n",
    "plt.figure(1,(12,5))\n",
    "for c, ekey in enumerate(ice_data.keys()):\n",
    "    plt.subplot(1,2,1)\n",
    "    v = ice_data[ekey]['NH_snow_volume']/1e12\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).max()[6:-5], color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='C'+str(c), linewidth=1)\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).min()[6:-5], color='C'+str(c), linewidth=1)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    v = ice_data[ekey]['SH_snow_volume']/1e12\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).max()[6:-5], color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='C'+str(c), linewidth=1)\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).min()[6:-5], color='C'+str(c), linewidth=1)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.ylim(ymin=0,ymax=5)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Year',font)\n",
    "plt.ylabel(r'Snow volume (10$^{12}$ m$^3$)',font)\n",
    "plt.title('Arctic snow volume minimum, mean and maximum',font)\n",
    "plt.subplot(1,2,2)\n",
    "plt.ylim(ymin=0,ymax=5)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Year',font)\n",
    "plt.ylabel(r'Snow volume (10$^{12}$ m$^3$)',font)\n",
    "plt.title('Antarctic snow volume minimum, mean and maximum',font)\n",
    "plt.legend(prop=font,loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "savefigure('snow_volume_min_mean_max_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12-mo running mean and timeseries of extent for all models\n",
    "plt.figure(1,(12,5))\n",
    "for c, ekey in enumerate(ice_data.keys()):\n",
    "    plt.subplot(1,2,1)\n",
    "    v = ice_data[ekey]['NH_extent']/1e12\n",
    "    plt.plot(v['time'],v, color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='C'+str(c), linewidth=2)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    v = ice_data[ekey]['SH_extent']/1e12\n",
    "    plt.plot(v['time'],v, color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='C'+str(c), linewidth=2)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "v = NH_obs.extent/1e12\n",
    "plt.plot(v['time'],v, color='k', linewidth=1, label='Observations')\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='k', linewidth=1)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "v = SH_obs.extent/1e12\n",
    "plt.plot(v['time'],v, color='k', linewidth=1, label='Observations')\n",
    "plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='k', linewidth=1)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.ylim(ymin=0,ymax=22)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Year',font)\n",
    "plt.ylabel(r'Sea ice extent (10$^{12}$ m$^2$)',font)\n",
    "plt.title('Arctic sea ice extent',font)\n",
    "plt.subplot(1,2,2)\n",
    "plt.ylim(ymin=0,ymax=22)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Year',font)\n",
    "plt.ylabel(r'Sea ice extent (10$^{12}$ m$^2$)',font)\n",
    "plt.title('Antarctic sea ice extent',font)\n",
    "plt.legend(prop=font,loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "savefigure('ice_extent_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12-mo running mean and timeseries of snow volume for all models\n",
    "plt.figure(1,(12,5))\n",
    "for c, ekey in enumerate(ice_data.keys()):\n",
    "    plt.subplot(1,2,1)\n",
    "    v = ice_data[ekey]['NH_snow_volume']/1e12\n",
    "    plt.plot(v['time'],v, color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='C'+str(c), linewidth=2)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    v = ice_data[ekey]['SH_snow_volume']/1e12\n",
    "    plt.plot(v['time'],v, color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "    plt.plot(v['time'][6:-5],v.rolling(time=12, center=True).mean()[6:-5], color='C'+str(c), linewidth=2)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.ylim(ymin=0,ymax=5)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Year',font)\n",
    "plt.ylabel(r'Snow volume (10$^{12}$ m$^3$)',font)\n",
    "plt.title('Arctic snow volume',font)\n",
    "plt.subplot(1,2,2)\n",
    "plt.ylim(ymin=0,ymax=5)\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Year',font)\n",
    "plt.ylabel(r'Snow volume (10$^{12}$ m$^3$)',font)\n",
    "plt.title('Antarctic snow volume',font)\n",
    "plt.legend(prop=font,loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "savefigure('snow_volume_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonal cycle of area for all models\n",
    "plt.figure(1,(12,5))\n",
    "for c, ekey in enumerate(ice_data.keys()):\n",
    "    plt.subplot(2,1,1)\n",
    "    v = ice_data[ekey]['NH_area']/1e12\n",
    "    v = v.sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)\n",
    "    plt.plot(v['month'],v, color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    v = ice_data[ekey]['SH_area']/1e12\n",
    "    v = v.sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)\n",
    "    plt.plot(v['month'],v, color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "v = NH_obs.area/1e12\n",
    "v = v.sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)\n",
    "plt.plot(v['month'],v, color='k', linewidth=1, label='Observations')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "v = SH_obs.area/1e12\n",
    "v = v.sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)\n",
    "plt.plot(v['month'],v, color='k', linewidth=1, label='Observations')\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.ylim(ymin=0)\n",
    "plt.xlabel('Month',font)\n",
    "plt.ylabel(r'Sea ice area (10$^{12}$ m$^2$)',font)\n",
    "plt.title('Arctic sea ice area '+yearrange+' mean annual cycle',font)\n",
    "plt.subplot(2,1,2)\n",
    "plt.ylim(ymin=0)\n",
    "plt.xlabel('Month',font)\n",
    "plt.ylabel(r'Sea ice area (10$^{12}$ m$^2$)',font)\n",
    "plt.title('Antarctic sea ice area '+yearrange+' mean annual cycle',font)\n",
    "plt.legend(prop=font,loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "savefigure('ice_area_seasonal_clim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonal cycle of extent for all models\n",
    "plt.figure(1,(12,5))\n",
    "for c, ekey in enumerate(ice_data.keys()):\n",
    "    plt.subplot(2,1,1)\n",
    "    v = ice_data[ekey]['NH_extent']/1e12\n",
    "    v = v.sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)\n",
    "    plt.plot(v['month'],v, color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    v = ice_data[ekey]['SH_extent']/1e12\n",
    "    v = v.sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)\n",
    "    plt.plot(v['month'],v, color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "v = NH_obs.extent/1e12\n",
    "v = v.sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)\n",
    "plt.plot(v['month'],v, color='k', linewidth=1, label='Observations')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "v = SH_obs.extent/1e12\n",
    "v = v.sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)\n",
    "plt.plot(v['month'],v, color='k', linewidth=1, label='Observations')\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.ylim(ymin=0)\n",
    "plt.xlabel('Month',font)\n",
    "plt.ylabel(r'Sea ice extent (10$^{12}$ m$^2$)',font)\n",
    "plt.title('Arctic sea ice extent '+yearrange+' mean annual cycle',font)\n",
    "plt.subplot(2,1,2)\n",
    "plt.ylim(ymin=0)\n",
    "plt.xlabel('Month',font)\n",
    "plt.ylabel(r'Sea ice extent (10$^{12}$ m$^23$)',font)\n",
    "plt.title('Antarctic sea ice extent '+yearrange+' mean annual cycle',font)\n",
    "plt.legend(prop=font,loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "savefigure('ice_extent_seasonal_clim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasonal cycle of snow volume for all models\n",
    "plt.figure(1,(12,5))\n",
    "for c, ekey in enumerate(ice_data.keys()):\n",
    "    plt.subplot(2,1,1)\n",
    "    v = ice_data[ekey]['NH_snow_volume']/1e12\n",
    "    v = v.sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)\n",
    "    plt.plot(v['month'],v, color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    v = ice_data[ekey]['SH_snow_volume']/1e12\n",
    "    v = v.sel(time=slice(tstart,tend)).groupby('time.month').mean('time', skipna=True)\n",
    "    plt.plot(v['month'],v, color='C'+str(c), linewidth=1, label=ice_data[ekey]['desc'])\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.ylim(ymin=0)\n",
    "plt.xlabel('Month',font)\n",
    "plt.ylabel(r'Snow volume (10$^{12}$ m$^3$)',font)\n",
    "plt.title('Arctic snow volume '+yearrange+' mean annual cycle',font)\n",
    "plt.subplot(2,1,2)\n",
    "plt.ylim(ymin=0)\n",
    "plt.xlabel('Month',font)\n",
    "plt.ylabel(r'Snow volume (10$^{12}$ m$^3$)',font)\n",
    "plt.title('Antarctic snow volume '+yearrange+' mean annual cycle',font)\n",
    "plt.legend(prop=font,loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "savefigure('snow_volume_seasonal_clim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-18.10]",
   "language": "python",
   "name": "conda-env-analysis3-18.10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
